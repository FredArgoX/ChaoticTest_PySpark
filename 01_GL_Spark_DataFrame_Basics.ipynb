{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMCJfFptW4VnBL/UzhtjyQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FredArgoX/ChaoticTest_PySpark/blob/main/01_GL_Spark_DataFrame_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: [Great Learning](https://olympus.mygreatlearning.com/courses/31729/modules/items/879875?pb_id=581)"
      ],
      "metadata": {
        "id": "4I-pejZFnixU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark DataFrames are the workhouse and main way of working with Spark and Python post Spark 2.0. DataFrames act as powerful versions of tables, with rows and columns, easily handling large datasets. The shift to DataFrames provides many advantages:\n",
        "\n",
        "- A much simpler syntax\n",
        "- Ability to use SQL directly in the dataframe\n",
        "- Operations are automatically distributed across RDDs\n",
        "\n",
        "If you've used R or even the pandas library with Python you are probably already familiar with the concept of DataFrames. Spark DataFrame expand on a lot of these concepts, allowing you to transfer that knowlwdge easily by understanding the simple syntax of Spark DataFrames. Remember that the main advantage to using Spark DataFrames vs those of other programs is that Spark cand handle data across many RDDs, huge data sets that would never fit on a single computer."
      ],
      "metadata": {
        "id": "sdvVPzPtkVUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a DataFrame"
      ],
      "metadata": {
        "id": "27Bn_GGGlpE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to start a SparkSession:"
      ],
      "metadata": {
        "id": "qlh1W8DHlv2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xkmyWYKtjhnB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then start the SparkSession"
      ],
      "metadata": {
        "id": "XQgcvOn7l7no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# May take a little while on a local computer\n",
        "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
      ],
      "metadata": {
        "id": "Y-ghLs_Cl4AJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "1CKrTbrGmLgF",
        "outputId": "11b330a8-7c56-46c5-c459-550105ce529f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7db675a1fc90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://1fbde26f49fc:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Basics</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will first need to get the data from a file (or connect to a large distributed file like HDFS)"
      ],
      "metadata": {
        "id": "WXpr-TZzmhzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This dataset is from Spark's examples\n",
        "# The json data is located on the link: https://raw.githubusercontent.com/FredArgoX/ChaoticTest_PySpark/refs/heads/main/data/people.json\n",
        "\n",
        "!wget https://raw.githubusercontent.com/FredArgoX/ChaoticTest_PySpark/refs/heads/main/data/people.json -O people.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRER84IXmrtp",
        "outputId": "9a5ecbaf-86d8-4903-ec4a-4dc65710e2b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-26 19:07:41--  https://raw.githubusercontent.com/FredArgoX/ChaoticTest_PySpark/refs/heads/main/data/people.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72 [text/plain]\n",
            "Saving to: ‘people.json’\n",
            "\n",
            "\rpeople.json           0%[                    ]       0  --.-KB/s               \rpeople.json         100%[===================>]      72  --.-KB/s    in 0s      \n",
            "\n",
            "2025-06-26 19:07:41 (4.47 MB/s) - ‘people.json’ saved [72/72]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "df = spark.read.json('people.json')"
      ],
      "metadata": {
        "id": "2s22UC6Noipu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showing the data"
      ],
      "metadata": {
        "id": "Cxy4hDg4pITp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkOW6ckSpDCU",
        "outputId": "10611385-e90f-4671-929c-1424c47f4a4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+\n",
            "| age|   name|\n",
            "+----+-------+\n",
            "|NULL|Michael|\n",
            "|  30|   Andy|\n",
            "|  19| Justin|\n",
            "+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj2VI3kcpNB4",
        "outputId": "e5b58d6f-3584-49b3-c8c6-21c5a4bfa94f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yds4brMpRfC",
        "outputId": "9f4b0604-1c5d-4663-a9c0-2973624d18bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'name']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yF1tcqIpU_7",
        "outputId": "64b6ced9-a124-4e23-925e-08299fc22ee6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, age: string, name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3-h_I32pXe2",
        "outputId": "3db80fb4-8808-4a26-8990-9578e1b959a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------+\n",
            "|summary|               age|   name|\n",
            "+-------+------------------+-------+\n",
            "|  count|                 2|      3|\n",
            "|   mean|              24.5|   NULL|\n",
            "| stddev|7.7781745930520225|   NULL|\n",
            "|    min|                19|   Andy|\n",
            "|    max|                30|Michael|\n",
            "+-------+------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some data types make it easier to infer schema (like tabular formats such as csv).\n",
        "\n",
        "However you often have to set the schema yourself if you aren't dealing with a .read method that doesn't have inferSchema() built-in.\n",
        "\n",
        "Spark has all the tools you need for this, it just requires a very specific structure:"
      ],
      "metadata": {
        "id": "h3GhyUg5prf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructField, StringType, IntegerType, StructType"
      ],
      "metadata": {
        "id": "ak1nhHjFpepR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to create the list of Structure fields * :param name: string, name of the field. * :param dataType: class:DataType of the field. * :param nullable: boolean, whether the field can be null (None) or not."
      ],
      "metadata": {
        "id": "njkd-rIdqgyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_schema = [\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"name\", StringType(), True)\n",
        "]"
      ],
      "metadata": {
        "id": "Bg-x7eUAqaFJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_struc = StructType(fields=data_schema)"
      ],
      "metadata": {
        "id": "0nd50BfWreNj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json(\"people.json\", schema=final_struc)"
      ],
      "metadata": {
        "id": "ChnVtgLTrj03"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZm9YQScrpW5",
        "outputId": "3e36d1bf-edb4-48b4-8307-8088d9832a3f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grabbing the data"
      ],
      "metadata": {
        "id": "rNwVnsT8rwQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "riqzSPI7rrCo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}